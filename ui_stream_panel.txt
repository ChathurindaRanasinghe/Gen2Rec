from asyncio import sleep

import httpx
import panel as pn

pn.extension()

# llm = ChatOpenAI(model="gpt-3.5-turbo",openai_api_key="sk-defaultkey-Mz8sBVKIHLV4ob31BqtkT3BlbkFJynOLG3ybmqaqsu2NMxaU")
client = httpx.Client(timeout=20)


async def gen2rec_callback(contents, user, instance):
    message = ""
    with client.stream(
        "GET",
        "http://localhost:8000/chat-stream",
        params={"query": contents},
    ) as response:
        for chunk in response.iter_text(chunk_size=1):
            await sleep(0.01)
            message += chunk
            yield message


# openai_callback
# chat_feed = pn.chat.ChatFeed(callback=openai_callback)
chat_interface = pn.chat.ChatInterface(
    callback=gen2rec_callback, callback_user="Gen2Rec"
)
chat_interface.servable()
